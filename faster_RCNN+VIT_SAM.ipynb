{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vn9sP9IOaB0F",
        "outputId": "72e9a534-d4d4-4139-a17a-a008defbb636"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (2.0.8)\n",
            "Requirement already satisfied: roboflow in /usr/local/lib/python3.11/dist-packages (1.1.54)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from roboflow) (2025.1.31)\n",
            "Requirement already satisfied: idna==3.7 in /usr/local/lib/python3.11/dist-packages (from roboflow) (3.7)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.11/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.4.8)\n",
            "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.11/dist-packages (from roboflow) (4.10.0.84)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.8.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.3.0)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision transformers opencv-python pycocotools roboflow matplotlib tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCU-Ednwab05",
        "outputId": "77e6018e-0fac-4d37-9398-826f3de32ba8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74JF7BMUarqL",
        "outputId": "a4d53646-5251-4b89-d4aa-97146f850de0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        }
      ],
      "source": [
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"vQsG0k1QDxbi74ZD03Wp\")\n",
        "project = rf.workspace(\"fire-detection-4mpgq\").project(\"root-cannel\")\n",
        "version = project.version(5)\n",
        "dataset = version.download(\"yolov5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gwo127_pavBm",
        "outputId": "34caa1a2-a986-4305-fea0-4770da239b6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Root-cannel-5/train/images\n",
            "/content/Root-cannel-5/train/labels\n"
          ]
        }
      ],
      "source": [
        "image_dir = f\"/content/Root-cannel-5/train/images\"\n",
        "annotation_dir = f\"/content/Root-cannel-5/train/labels\"\n",
        "print(image_dir)\n",
        "print(annotation_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "6tDRrVbXavv0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import os\n",
        "import cv2\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, image_dir, annotation_dir):\n",
        "        self.image_dir = image_dir\n",
        "        self.annotation_dir = annotation_dir\n",
        "        self.image_files = [f for f in os.listdir(image_dir) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.image_files[idx]\n",
        "        img_path = os.path.join(self.image_dir, img_name)\n",
        "        ann_path = os.path.join(self.annotation_dir, img_name.replace('.jpg', '.txt'))\n",
        "\n",
        "        # Load image\n",
        "        image = cv2.imread(img_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = torch.tensor(image).permute(2, 0, 1).float() / 255.0\n",
        "\n",
        "        # Load annotations (YOLO format)\n",
        "        boxes, labels = [], []\n",
        "        with open(ann_path, \"r\") as file:\n",
        "            for line in file.readlines():\n",
        "                data = list(map(float, line.strip().split()))\n",
        "                label, x_center, y_center, width, height = data\n",
        "                x1 = (x_center - width / 2) * image.shape[2]\n",
        "                y1 = (y_center - height / 2) * image.shape[1]\n",
        "                x2 = (x_center + width / 2) * image.shape[2]\n",
        "                y2 = (y_center + height / 2) * image.shape[1]\n",
        "                boxes.append([x1, y1, x2, y2])\n",
        "                labels.append(int(label))\n",
        "\n",
        "        target = {\"boxes\": torch.tensor(boxes, dtype=torch.float32), \"labels\": torch.tensor(labels, dtype=torch.int64)}\n",
        "        return image, target\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "FoJK6lP9axZq"
      },
      "outputs": [],
      "source": [
        "from transformers import SwinModel\n",
        "\n",
        "swin_backbone = SwinModel.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\")\n",
        "backbone = swin_backbone\n",
        "backbone.out_channels = 768\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-xFsRq2Naza5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2b48340-5519-42a8-8cee-7605d7c4867c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FasterRCNN(\n",
              "  (transform): GeneralizedRCNNTransform(\n",
              "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
              "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
              "  )\n",
              "  (backbone): SwinModel(\n",
              "    (embeddings): SwinEmbeddings(\n",
              "      (patch_embeddings): SwinPatchEmbeddings(\n",
              "        (projection): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
              "      )\n",
              "      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (encoder): SwinEncoder(\n",
              "      (layers): ModuleList(\n",
              "        (0): SwinStage(\n",
              "          (blocks): ModuleList(\n",
              "            (0): SwinLayer(\n",
              "              (layernorm_before): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): SwinAttention(\n",
              "                (self): SwinSelfAttention(\n",
              "                  (query): Linear(in_features=96, out_features=96, bias=True)\n",
              "                  (key): Linear(in_features=96, out_features=96, bias=True)\n",
              "                  (value): Linear(in_features=96, out_features=96, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): SwinSelfOutput(\n",
              "                  (dense): Linear(in_features=96, out_features=96, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): Identity()\n",
              "              (layernorm_after): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): SwinIntermediate(\n",
              "                (dense): Linear(in_features=96, out_features=384, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): SwinOutput(\n",
              "                (dense): Linear(in_features=384, out_features=96, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (1): SwinLayer(\n",
              "              (layernorm_before): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): SwinAttention(\n",
              "                (self): SwinSelfAttention(\n",
              "                  (query): Linear(in_features=96, out_features=96, bias=True)\n",
              "                  (key): Linear(in_features=96, out_features=96, bias=True)\n",
              "                  (value): Linear(in_features=96, out_features=96, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): SwinSelfOutput(\n",
              "                  (dense): Linear(in_features=96, out_features=96, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): SwinDropPath(p=0.00909090880304575)\n",
              "              (layernorm_after): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): SwinIntermediate(\n",
              "                (dense): Linear(in_features=96, out_features=384, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): SwinOutput(\n",
              "                (dense): Linear(in_features=384, out_features=96, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (downsample): SwinPatchMerging(\n",
              "            (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
              "            (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (1): SwinStage(\n",
              "          (blocks): ModuleList(\n",
              "            (0): SwinLayer(\n",
              "              (layernorm_before): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): SwinAttention(\n",
              "                (self): SwinSelfAttention(\n",
              "                  (query): Linear(in_features=192, out_features=192, bias=True)\n",
              "                  (key): Linear(in_features=192, out_features=192, bias=True)\n",
              "                  (value): Linear(in_features=192, out_features=192, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): SwinSelfOutput(\n",
              "                  (dense): Linear(in_features=192, out_features=192, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): SwinDropPath(p=0.0181818176060915)\n",
              "              (layernorm_after): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): SwinIntermediate(\n",
              "                (dense): Linear(in_features=192, out_features=768, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): SwinOutput(\n",
              "                (dense): Linear(in_features=768, out_features=192, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (1): SwinLayer(\n",
              "              (layernorm_before): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): SwinAttention(\n",
              "                (self): SwinSelfAttention(\n",
              "                  (query): Linear(in_features=192, out_features=192, bias=True)\n",
              "                  (key): Linear(in_features=192, out_features=192, bias=True)\n",
              "                  (value): Linear(in_features=192, out_features=192, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): SwinSelfOutput(\n",
              "                  (dense): Linear(in_features=192, out_features=192, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): SwinDropPath(p=0.027272727340459824)\n",
              "              (layernorm_after): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): SwinIntermediate(\n",
              "                (dense): Linear(in_features=192, out_features=768, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): SwinOutput(\n",
              "                (dense): Linear(in_features=768, out_features=192, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (downsample): SwinPatchMerging(\n",
              "            (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (2): SwinStage(\n",
              "          (blocks): ModuleList(\n",
              "            (0): SwinLayer(\n",
              "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): SwinAttention(\n",
              "                (self): SwinSelfAttention(\n",
              "                  (query): Linear(in_features=384, out_features=384, bias=True)\n",
              "                  (key): Linear(in_features=384, out_features=384, bias=True)\n",
              "                  (value): Linear(in_features=384, out_features=384, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): SwinSelfOutput(\n",
              "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): SwinDropPath(p=0.036363635212183)\n",
              "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): SwinIntermediate(\n",
              "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): SwinOutput(\n",
              "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (1): SwinLayer(\n",
              "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): SwinAttention(\n",
              "                (self): SwinSelfAttention(\n",
              "                  (query): Linear(in_features=384, out_features=384, bias=True)\n",
              "                  (key): Linear(in_features=384, out_features=384, bias=True)\n",
              "                  (value): Linear(in_features=384, out_features=384, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): SwinSelfOutput(\n",
              "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): SwinDropPath(p=0.045454543083906174)\n",
              "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): SwinIntermediate(\n",
              "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): SwinOutput(\n",
              "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (2): SwinLayer(\n",
              "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): SwinAttention(\n",
              "                (self): SwinSelfAttention(\n",
              "                  (query): Linear(in_features=384, out_features=384, bias=True)\n",
              "                  (key): Linear(in_features=384, out_features=384, bias=True)\n",
              "                  (value): Linear(in_features=384, out_features=384, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): SwinSelfOutput(\n",
              "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): SwinDropPath(p=0.054545458406209946)\n",
              "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): SwinIntermediate(\n",
              "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): SwinOutput(\n",
              "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (3): SwinLayer(\n",
              "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): SwinAttention(\n",
              "                (self): SwinSelfAttention(\n",
              "                  (query): Linear(in_features=384, out_features=384, bias=True)\n",
              "                  (key): Linear(in_features=384, out_features=384, bias=True)\n",
              "                  (value): Linear(in_features=384, out_features=384, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): SwinSelfOutput(\n",
              "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): SwinDropPath(p=0.06363636255264282)\n",
              "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): SwinIntermediate(\n",
              "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): SwinOutput(\n",
              "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (4): SwinLayer(\n",
              "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): SwinAttention(\n",
              "                (self): SwinSelfAttention(\n",
              "                  (query): Linear(in_features=384, out_features=384, bias=True)\n",
              "                  (key): Linear(in_features=384, out_features=384, bias=True)\n",
              "                  (value): Linear(in_features=384, out_features=384, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): SwinSelfOutput(\n",
              "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): SwinDropPath(p=0.0727272778749466)\n",
              "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): SwinIntermediate(\n",
              "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): SwinOutput(\n",
              "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (5): SwinLayer(\n",
              "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): SwinAttention(\n",
              "                (self): SwinSelfAttention(\n",
              "                  (query): Linear(in_features=384, out_features=384, bias=True)\n",
              "                  (key): Linear(in_features=384, out_features=384, bias=True)\n",
              "                  (value): Linear(in_features=384, out_features=384, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): SwinSelfOutput(\n",
              "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): SwinDropPath(p=0.08181818574666977)\n",
              "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): SwinIntermediate(\n",
              "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): SwinOutput(\n",
              "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (downsample): SwinPatchMerging(\n",
              "            (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
              "            (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (3): SwinStage(\n",
              "          (blocks): ModuleList(\n",
              "            (0): SwinLayer(\n",
              "              (layernorm_before): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): SwinAttention(\n",
              "                (self): SwinSelfAttention(\n",
              "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): SwinSelfOutput(\n",
              "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): SwinDropPath(p=0.09090909361839294)\n",
              "              (layernorm_after): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): SwinIntermediate(\n",
              "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): SwinOutput(\n",
              "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (1): SwinLayer(\n",
              "              (layernorm_before): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): SwinAttention(\n",
              "                (self): SwinSelfAttention(\n",
              "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): SwinSelfOutput(\n",
              "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): SwinDropPath(p=0.10000000149011612)\n",
              "              (layernorm_after): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): SwinIntermediate(\n",
              "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): SwinOutput(\n",
              "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    (pooler): AdaptiveAvgPool1d(output_size=1)\n",
              "  )\n",
              "  (rpn): RegionProposalNetwork(\n",
              "    (anchor_generator): AnchorGenerator()\n",
              "    (head): RPNHead(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2dNormActivation(\n",
              "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (cls_logits): Conv2d(768, 15, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (bbox_pred): Conv2d(768, 60, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (roi_heads): RoIHeads(\n",
              "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
              "    (box_head): TwoMLPHead(\n",
              "      (fc6): Linear(in_features=37632, out_features=1024, bias=True)\n",
              "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "    )\n",
              "    (box_predictor): FastRCNNPredictor(\n",
              "      (cls_score): Linear(in_features=1024, out_features=10, bias=True)\n",
              "      (bbox_pred): Linear(in_features=1024, out_features=40, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "from torchvision.models.detection import FasterRCNN\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "\n",
        "anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256, 512),), aspect_ratios=((0.5, 1.0, 2.0),) * 5)\n",
        "\n",
        "model = FasterRCNN(backbone, num_classes=10, rpn_anchor_generator=anchor_generator)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsAyD91lhCHR",
        "outputId": "4be4889e-7b45-4583-d8d6-683f55d50678"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SamModel(\n",
              "  (shared_image_embedding): SamPositionalEmbedding()\n",
              "  (vision_encoder): SamVisionEncoder(\n",
              "    (patch_embed): SamPatchEmbeddings(\n",
              "      (projection): Conv2d(3, 1280, kernel_size=(16, 16), stride=(16, 16))\n",
              "    )\n",
              "    (layers): ModuleList(\n",
              "      (0-31): 32 x SamVisionLayer(\n",
              "        (layer_norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): SamVisionAttention(\n",
              "          (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
              "          (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        )\n",
              "        (layer_norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): SamMLPBlock(\n",
              "          (lin1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "          (lin2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "          (act): GELUActivation()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (neck): SamVisionNeck(\n",
              "      (conv1): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (layer_norm1): SamLayerNorm()\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (layer_norm2): SamLayerNorm()\n",
              "    )\n",
              "  )\n",
              "  (prompt_encoder): SamPromptEncoder(\n",
              "    (shared_embedding): SamPositionalEmbedding()\n",
              "    (mask_embed): SamMaskEmbedding(\n",
              "      (activation): GELUActivation()\n",
              "      (conv1): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))\n",
              "      (conv2): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))\n",
              "      (conv3): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (layer_norm1): SamLayerNorm()\n",
              "      (layer_norm2): SamLayerNorm()\n",
              "    )\n",
              "    (no_mask_embed): Embedding(1, 256)\n",
              "    (point_embed): ModuleList(\n",
              "      (0-3): 4 x Embedding(1, 256)\n",
              "    )\n",
              "    (not_a_point_embed): Embedding(1, 256)\n",
              "  )\n",
              "  (mask_decoder): SamMaskDecoder(\n",
              "    (iou_token): Embedding(1, 256)\n",
              "    (mask_tokens): Embedding(4, 256)\n",
              "    (transformer): SamTwoWayTransformer(\n",
              "      (layers): ModuleList(\n",
              "        (0-1): 2 x SamTwoWayAttentionBlock(\n",
              "          (self_attn): SamAttention(\n",
              "            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "          )\n",
              "          (layer_norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "          (cross_attn_token_to_image): SamAttention(\n",
              "            (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
              "            (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
              "            (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
              "            (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
              "          )\n",
              "          (layer_norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): SamMLPBlock(\n",
              "            (lin1): Linear(in_features=256, out_features=2048, bias=True)\n",
              "            (lin2): Linear(in_features=2048, out_features=256, bias=True)\n",
              "            (act): ReLU()\n",
              "          )\n",
              "          (layer_norm3): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "          (layer_norm4): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
              "          (cross_attn_image_to_token): SamAttention(\n",
              "            (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
              "            (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
              "            (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
              "            (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (final_attn_token_to_image): SamAttention(\n",
              "        (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
              "        (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
              "        (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
              "        (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
              "      )\n",
              "      (layer_norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (upscale_conv1): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))\n",
              "    (upscale_conv2): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
              "    (upscale_layer_norm): SamLayerNorm()\n",
              "    (activation): GELU(approximate='none')\n",
              "    (output_hypernetworks_mlps): ModuleList(\n",
              "      (0-3): 4 x SamFeedForward(\n",
              "        (activation): ReLU()\n",
              "        (proj_in): Linear(in_features=256, out_features=256, bias=True)\n",
              "        (proj_out): Linear(in_features=256, out_features=32, bias=True)\n",
              "        (layers): ModuleList(\n",
              "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (iou_prediction_head): SamFeedForward(\n",
              "      (activation): ReLU()\n",
              "      (proj_in): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (proj_out): Linear(in_features=256, out_features=4, bias=True)\n",
              "      (layers): ModuleList(\n",
              "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "from transformers import SamModel, SamProcessor\n",
        "\n",
        "sam_model = SamModel.from_pretrained(\"facebook/sam-vit-huge\")\n",
        "sam_processor = SamProcessor.from_pretrained(\"facebook/sam-vit-huge\")\n",
        "sam_model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomDataset(image_dir, annotation_dir)\n",
        "data_loader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))"
      ],
      "metadata": {
        "id": "w3rc6l6Co4oa"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "num_epochs = 5\n",
        "\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for images, targets in tqdm(data_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
        "        images = [img.to(device) for img in images]\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss_dict = model(images, targets)\n",
        "        loss = sum(loss for loss in loss_dict.values())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "5_JOvJm4pQ2d",
        "outputId": "92e7df1a-4fd3-4910-f781-ee344f34aede"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5:   0%|          | 0/113 [00:01<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Given groups=1, weight of size [768, 768, 3, 3], expected input[1, 4, 625, 768] to have 768 channels, but got 4 channels instead",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-4775c6d2fd69>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mloss_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloss_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/models/detection/generalized_rcnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mproposals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposal_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0mdetections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetector_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroi_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproposals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mdetections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_image_sizes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[operator]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/models/detection/rpn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, features, targets)\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0;31m# RPN uses all feature maps that are available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m         \u001b[0mobjectness\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_bbox_deltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m         \u001b[0manchors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manchor_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/models/detection/rpn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mbbox_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mbbox_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbbox_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             )\n\u001b[0;32m--> 549\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [768, 768, 3, 3], expected input[1, 4, 625, 768] to have 768 channels, but got 4 channels instead"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")\n"
      ],
      "metadata": {
        "id": "XqmvcxQGpv_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def detect_and_segment(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image_tensor = torch.tensor(image).permute(2, 0, 1).unsqueeze(0).float().to(device)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        detections = model(image_tensor)\n",
        "\n",
        "    boxes = detections[0]['boxes'].cpu().numpy()\n",
        "\n",
        "    # Run SAM on the detected image\n",
        "    inputs = sam_processor(images=image, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        masks = sam_model(**inputs).last_hidden_state\n",
        "\n",
        "    for box in boxes:\n",
        "        x1, y1, x2, y2 = map(int, box)\n",
        "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "    plt.imshow(image)\n",
        "    plt.title(\"Object Detection + SAM Segmentation\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "# Test on a sample image\n",
        "test_image = f\"./{project.name}-{project.version}/test/images/example.jpg\"\n",
        "detect_and_segment(test_image)\n"
      ],
      "metadata": {
        "id": "2E6PMJ-1pzU6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}